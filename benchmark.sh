export GPU_MAX_HW_QUEUES=2
export TORCH_NCCL_HIGH_PRIORITY=1



#bash train_llama2_13b.sh MODEL_SIZE=70 MBS=4 TP=8 PP=1 BS=32 SEQ_LENGTH=4096 SEQ_PARALLEL=1 USE_FLASH_ATTN=1 TE_FP16=0 NO_TORCH_COMPILE=0 TOTAL_ITERS=2 TEE_OUTPUT=1 OPTIMIZER=sgd TORCH_PROFILE=1 TRACE_DIR="/root/.cache/Megatron-LM/trace_70B"

bash train_llama2_13b.sh MODEL_SIZE=70 MBS=1 TP=8 PP=1 BS=8 SEQ_LENGTH=4096 SEQ_PARALLEL=1 USE_FLASH_ATTN=1 TE_FP16=0 NO_TORCH_COMPILE=0 TOTAL_ITERS=4 TEE_OUTPUT=1 OPTIMIZER=sgd 